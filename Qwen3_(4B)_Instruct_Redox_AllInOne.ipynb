{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Redox All-in-One Colab: Rust + Iron Fine-tune, Predict, Evaluate\n",
        "\n",
        "Run this notebook with **Runtime -> Run all**.\n",
        "\n",
        "It will, in one run:\n",
        "1. Train **Rust arm** adapter.\n",
        "2. Generate Rust test predictions JSONL.\n",
        "3. Train **Iron arm** adapter.\n",
        "4. Generate Iron test predictions JSONL.\n",
        "5. Repeat for each seed in `SEEDS`.\n",
        "6. Evaluate each seed and write an aggregate report.\n",
        "\n",
        "Expected Google Drive layout:\n",
        "- `/content/drive/MyDrive/redox/`\n",
        "- dataset files under `data/pilot/<version>/unsloth/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "REPO_DIR = Path('/content/drive/MyDrive/redox').resolve()\n",
        "\n",
        "# Prefer this dataset version first; notebook will auto-fallback if missing.\n",
        "PREFERRED_DATA_VERSION = 'foundation_v2'\n",
        "\n",
        "BASE_MODEL = 'unsloth/Qwen3-4B-Instruct-2507'\n",
        "SEEDS = [3407, 2108]\n",
        "ARMS = ['rust', 'iron']\n",
        "MAX_SEQ_LENGTH = 2048\n",
        "MAX_NEW_TOKENS = 320\n",
        "NUM_TRAIN_EPOCHS = 1\n",
        "\n",
        "stamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "RUN_TAG = f'all_in_one_qwen3_4b_multiseed_{stamp}'\n",
        "TRAINING_ROOT = REPO_DIR / 'training' / 'all_in_one' / RUN_TAG\n",
        "EVAL_ROOT = REPO_DIR / 'eval' / 'all_in_one' / RUN_TAG\n",
        "TRAINING_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "EVAL_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "\n",
        "def has_required_files(data_dir: Path) -> bool:\n",
        "    required = []\n",
        "    for arm in ARMS:\n",
        "        required.extend([\n",
        "            data_dir / f'{arm}_train.jsonl',\n",
        "            data_dir / f'{arm}_val.jsonl',\n",
        "            data_dir / f'{arm}_test.jsonl',\n",
        "        ])\n",
        "    return all(p.exists() for p in required)\n",
        "\n",
        "\n",
        "candidate_versions = [\n",
        "    PREFERRED_DATA_VERSION,\n",
        "    'foundation_v2',\n",
        "    'foundation_v1',\n",
        "]\n",
        "# Preserve order but remove duplicates\n",
        "candidate_versions = list(dict.fromkeys(candidate_versions))\n",
        "\n",
        "DATA_VERSION = None\n",
        "DATA_DIR = None\n",
        "for version in candidate_versions:\n",
        "    candidate = REPO_DIR / 'data' / 'pilot' / version / 'unsloth'\n",
        "    if has_required_files(candidate):\n",
        "        DATA_VERSION = version\n",
        "        DATA_DIR = candidate\n",
        "        break\n",
        "\n",
        "if DATA_DIR is None:\n",
        "    searched = [str(REPO_DIR / 'data' / 'pilot' / v / 'unsloth') for v in candidate_versions]\n",
        "    raise FileNotFoundError(\n",
        "        'Could not find dataset with required files for both arms.\\n'\n",
        "        'Expected files: rust_{train,val,test}.jsonl and iron_{train,val,test}.jsonl\\n'\n",
        "        'Searched:\\n' + '\\n'.join(searched)\n",
        "    )\n",
        "\n",
        "print('Repo dir:', REPO_DIR)\n",
        "print('Data version:', DATA_VERSION)\n",
        "print('Data dir:', DATA_DIR)\n",
        "print('Run tag :', RUN_TAG)\n",
        "print('Seeds   :', SEEDS)\n",
        "print('Training outputs:', TRAINING_ROOT)\n",
        "print('Eval outputs:', EVAL_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if 'COLAB_' not in ''.join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    import torch\n",
        "    v = re.match(r'[\\d]{1,}\\.[\\d]{1,}', str(torch.__version__)).group(0)\n",
        "    xformers = 'xformers==' + {'2.10':'0.0.34','2.9':'0.0.33.post1','2.8':'0.0.32.post2'}.get(v, '0.0.34')\n",
        "    !pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth_zoo bitsandbytes accelerate {xformers} peft trl triton unsloth\n",
        "!pip install transformers==4.56.2\n",
        "!pip install --no-deps trl==0.22.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "if shutil.which('cargo') is None:\n",
        "    !curl https://sh.rustup.rs -sSf | sh -s -- -y\n",
        "    os.environ['PATH'] += ':/root/.cargo/bin'\n",
        "\n",
        "!cargo --version\n",
        "!rustc --version\n",
        "!cargo build --release --bin redox\n",
        "\n",
        "REDOX_CMD = str(REPO_DIR / 'target' / 'release' / 'redox')\n",
        "print('Redox binary:', REDOX_CMD)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "import inspect\n",
        "import json\n",
        "import re\n",
        "from typing import Any\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "from unsloth.chat_templates import (\n",
        "    get_chat_template,\n",
        "    standardize_data_formats,\n",
        "    train_on_responses_only,\n",
        ")\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "def load_jsonl(path: Path) -> list[dict[str, Any]]:\n",
        "    rows = []\n",
        "    for line in path.read_text(encoding='utf-8').splitlines():\n",
        "        if line.strip():\n",
        "            rows.append(json.loads(line))\n",
        "    return rows\n",
        "\n",
        "\n",
        "def get_user_prompt(row: dict[str, Any]) -> str:\n",
        "    for msg in row.get('conversations', []):\n",
        "        if msg.get('role') == 'user':\n",
        "            return msg.get('content', '')\n",
        "    return ''\n",
        "\n",
        "\n",
        "def clean_generation(text: str) -> str:\n",
        "    out = text.strip()\n",
        "    if out.startswith('```'):\n",
        "        out = re.sub(r'^```[A-Za-z0-9_-]*\\n', '', out)\n",
        "        out = re.sub(r'\\n```\\s*$', '', out)\n",
        "    return out.strip()\n",
        "\n",
        "\n",
        "def build_model_and_tokenizer(seed: int):\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name=BASE_MODEL,\n",
        "        max_seq_length=MAX_SEQ_LENGTH,\n",
        "        load_in_4bit=True,\n",
        "        load_in_8bit=False,\n",
        "        full_finetuning=False,\n",
        "    )\n",
        "\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "        model,\n",
        "        r=32,\n",
        "        target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'],\n",
        "        lora_alpha=32,\n",
        "        lora_dropout=0,\n",
        "        bias='none',\n",
        "        use_gradient_checkpointing='unsloth',\n",
        "        random_state=seed,\n",
        "        use_rslora=False,\n",
        "        loftq_config=None,\n",
        "    )\n",
        "\n",
        "    tokenizer = get_chat_template(tokenizer, chat_template='qwen3-instruct')\n",
        "    return model, tokenizer\n",
        "\n",
        "\n",
        "def format_dataset_for_sft(dataset_split, tokenizer):\n",
        "    ds = standardize_data_formats(dataset_split)\n",
        "\n",
        "    def formatting_prompts_func(examples):\n",
        "        convos = examples['conversations']\n",
        "        texts = [\n",
        "            tokenizer.apply_chat_template(c, tokenize=False, add_generation_prompt=False)\n",
        "            for c in convos\n",
        "        ]\n",
        "        return {'text': texts}\n",
        "\n",
        "    return ds.map(formatting_prompts_func, batched=True)\n",
        "\n",
        "\n",
        "def generate_once(model, tokenizer, messages):\n",
        "    rendered = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "    )\n",
        "    model_inputs = tokenizer(rendered, return_tensors='pt').to(next(model.parameters()).device)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        outputs = model.generate(\n",
        "            **model_inputs,\n",
        "            max_new_tokens=MAX_NEW_TOKENS,\n",
        "            do_sample=False,\n",
        "            temperature=0.0,\n",
        "            top_p=1.0,\n",
        "            use_cache=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    new_tokens = outputs[0][model_inputs['input_ids'].shape[1]:]\n",
        "    return clean_generation(tokenizer.decode(new_tokens, skip_special_tokens=True))\n",
        "\n",
        "\n",
        "def train_and_predict_arm(arm: str, seed: int) -> dict[str, str]:\n",
        "    arm_train = DATA_DIR / f'{arm}_train.jsonl'\n",
        "    arm_val = DATA_DIR / f'{arm}_val.jsonl'\n",
        "    arm_test = DATA_DIR / f'{arm}_test.jsonl'\n",
        "\n",
        "    ds = load_dataset(\n",
        "        'json',\n",
        "        data_files={\n",
        "            'train': str(arm_train),\n",
        "            'validation': str(arm_val),\n",
        "            'test': str(arm_test),\n",
        "        },\n",
        "    )\n",
        "\n",
        "    model, tokenizer = build_model_and_tokenizer(seed)\n",
        "\n",
        "    train_dataset = format_dataset_for_sft(ds['train'], tokenizer)\n",
        "    val_dataset = format_dataset_for_sft(ds['validation'], tokenizer)\n",
        "\n",
        "    run_name = f'qwen3-4b-redox-{arm}-seed{seed}'\n",
        "    run_dir = TRAINING_ROOT / run_name\n",
        "    run_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    trainer_kwargs = {\n",
        "        'model': model,\n",
        "        'train_dataset': train_dataset,\n",
        "        'eval_dataset': val_dataset,\n",
        "        'args': SFTConfig(\n",
        "            dataset_text_field='text',\n",
        "            per_device_train_batch_size=2,\n",
        "            gradient_accumulation_steps=4,\n",
        "            warmup_steps=5,\n",
        "            num_train_epochs=NUM_TRAIN_EPOCHS,\n",
        "            learning_rate=2e-4,\n",
        "            logging_steps=10,\n",
        "            eval_steps=50,\n",
        "            eval_strategy='steps',\n",
        "            save_steps=50,\n",
        "            save_total_limit=2,\n",
        "            optim='adamw_8bit',\n",
        "            weight_decay=0.001,\n",
        "            lr_scheduler_type='linear',\n",
        "            seed=seed,\n",
        "            report_to='none',\n",
        "            output_dir=str(run_dir),\n",
        "            bf16=is_bfloat16_supported(),\n",
        "            fp16=not is_bfloat16_supported(),\n",
        "        ),\n",
        "    }\n",
        "\n",
        "    trainer_sig = inspect.signature(SFTTrainer.__init__)\n",
        "    if 'tokenizer' in trainer_sig.parameters:\n",
        "        trainer_kwargs['tokenizer'] = tokenizer\n",
        "    elif 'processing_class' in trainer_sig.parameters:\n",
        "        trainer_kwargs['processing_class'] = tokenizer\n",
        "\n",
        "    trainer = SFTTrainer(**trainer_kwargs)\n",
        "\n",
        "    trainer = train_on_responses_only(\n",
        "        trainer,\n",
        "        instruction_part='<|im_start|>user\\n',\n",
        "        response_part='<|im_start|>assistant\\n',\n",
        "    )\n",
        "\n",
        "    print(f'\\n=== Training {arm.upper()} arm @ seed {seed} ===')\n",
        "    train_result = trainer.train()\n",
        "    print(train_result)\n",
        "\n",
        "    adapter_dir = run_dir / 'final_adapter'\n",
        "    trainer.model.save_pretrained(str(adapter_dir))\n",
        "    tokenizer.save_pretrained(str(adapter_dir))\n",
        "\n",
        "    FastLanguageModel.for_inference(model)\n",
        "    model.eval()\n",
        "\n",
        "    test_rows = load_jsonl(arm_test)\n",
        "    pred_path = EVAL_ROOT / f'predictions_{arm}_seed{seed}.jsonl'\n",
        "\n",
        "    with pred_path.open('w', encoding='utf-8') as f:\n",
        "        for row in tqdm(test_rows, desc=f'Generating {arm} predictions seed={seed}'):\n",
        "            prompt = get_user_prompt(row)\n",
        "            prediction = generate_once(model, tokenizer, [{'role': 'user', 'content': prompt}])\n",
        "\n",
        "            out_row = {\n",
        "                'id': row.get('id'),\n",
        "                'family': row.get('family'),\n",
        "                'split': row.get('split', 'test'),\n",
        "                'arm': arm,\n",
        "                'prompt': prompt,\n",
        "                'prediction': prediction,\n",
        "            }\n",
        "            f.write(json.dumps(out_row, ensure_ascii=True) + '\\n')\n",
        "\n",
        "    del trainer, model, tokenizer, train_dataset, val_dataset, ds\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return {\n",
        "        'adapter_dir': str(adapter_dir),\n",
        "        'predictions': str(pred_path),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_by_seed = {}\n",
        "for seed in SEEDS:\n",
        "    print(f'\\n================ SEED {seed} ================')\n",
        "    seed_results = {}\n",
        "    for arm in ARMS:\n",
        "        seed_results[arm] = train_and_predict_arm(arm, seed)\n",
        "    results_by_seed[str(seed)] = seed_results\n",
        "\n",
        "print('\\nCompleted arm runs by seed:')\n",
        "print(json.dumps(results_by_seed, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import subprocess\n",
        "\n",
        "report_paths = []\n",
        "for seed in SEEDS:\n",
        "    rust_preds = Path(results_by_seed[str(seed)]['rust']['predictions'])\n",
        "    iron_preds = Path(results_by_seed[str(seed)]['iron']['predictions'])\n",
        "    report_path = EVAL_ROOT / f'report_seed{seed}.json'\n",
        "\n",
        "    cmd = [\n",
        "        'python3',\n",
        "        'scripts/evaluate_predictions.py',\n",
        "        '--rust', str(rust_preds),\n",
        "        '--iron', str(iron_preds),\n",
        "        '--redox-cmd', REDOX_CMD,\n",
        "        '--out', str(report_path),\n",
        "    ]\n",
        "    print('Running:', ' '.join(cmd))\n",
        "    proc = subprocess.run(cmd, text=True, capture_output=True, check=False)\n",
        "    print(proc.stdout)\n",
        "    if proc.returncode != 0:\n",
        "        print(proc.stderr)\n",
        "        raise RuntimeError(f'Evaluation failed for seed {seed}')\n",
        "\n",
        "    report_paths.append(str(report_path))\n",
        "\n",
        "aggregate_report = None\n",
        "if len(report_paths) >= 2:\n",
        "    aggregate_report = str(EVAL_ROOT / 'report_aggregate_multiseed.json')\n",
        "    agg_cmd = ['python3', 'scripts/aggregate_eval_reports.py', *report_paths, '--out', aggregate_report]\n",
        "    print('Running:', ' '.join(agg_cmd))\n",
        "    agg = subprocess.run(agg_cmd, text=True, capture_output=True, check=False)\n",
        "    print(agg.stdout)\n",
        "    if agg.returncode != 0:\n",
        "        print(agg.stderr)\n",
        "        raise RuntimeError('Aggregate report generation failed')\n",
        "\n",
        "summary_path = EVAL_ROOT / 'run_summary.json'\n",
        "summary_path.write_text(\n",
        "    json.dumps(\n",
        "        {\n",
        "            'repo_dir': str(REPO_DIR),\n",
        "            'data_dir': str(DATA_DIR),\n",
        "            'run_tag': RUN_TAG,\n",
        "            'seeds': SEEDS,\n",
        "            'training_root': str(TRAINING_ROOT),\n",
        "            'eval_root': str(EVAL_ROOT),\n",
        "            'results_by_seed': results_by_seed,\n",
        "            'seed_reports': report_paths,\n",
        "            'aggregate_report': aggregate_report,\n",
        "        },\n",
        "        indent=2,\n",
        "    ) + '\\n',\n",
        "    encoding='utf-8',\n",
        ")\n",
        "\n",
        "print('Seed reports:')\n",
        "for p in report_paths:\n",
        "    print('-', p)\n",
        "if aggregate_report:\n",
        "    print('Aggregate report:', aggregate_report)\n",
        "print('Saved run summary:', summary_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outputs\n",
        "\n",
        "All outputs are stored under your Drive folder:\n",
        "\n",
        "- Training artifacts: `training/all_in_one/<run_tag>/`\n",
        "- Per-seed predictions and reports: `eval/all_in_one/<run_tag>/`\n",
        "- Multi-seed aggregate report: `eval/all_in_one/<run_tag>/report_aggregate_multiseed.json`\n",
        "- Run metadata: `eval/all_in_one/<run_tag>/run_summary.json`\n",
        "\n",
        "You can compare the aggregate report directly against your previous baselines.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    },
    "colab": {
      "name": "Qwen3_(4B)_Instruct_Redox_AllInOne.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}