{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Qwen3 4B Instruct - Redox Rust/Iron Finetune\n",
        "\n",
        "This notebook adapts the Unsloth Qwen3 flow for the Redox dataset exports.\n",
        "\n",
        "Before running, upload or mount files under:\n",
        "- `/content/data/pilot/foundation_v1/unsloth/`\n",
        "\n",
        "Expected files:\n",
        "- `rust_train.jsonl`, `rust_val.jsonl`, `rust_test.jsonl`\n",
        "- `iron_train.jsonl`, `iron_val.jsonl`, `iron_test.jsonl`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    import torch\n",
        "    v = re.match(r'[\\d]{1,}\\.[\\d]{1,}', str(torch.__version__)).group(0)\n",
        "    xformers = 'xformers==' + {'2.10':'0.0.34','2.9':'0.0.33.post1','2.8':'0.0.32.post2'}.get(v, \"0.0.34\")\n",
        "    !pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth_zoo bitsandbytes accelerate {xformers} peft trl triton unsloth\n",
        "!pip install transformers==4.56.2\n",
        "!pip install --no-deps trl==0.22.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Qwen3-4B-Instruct-2507\",\n",
        "    max_seq_length = 2048,\n",
        "    load_in_4bit = True,\n",
        "    load_in_8bit = False,\n",
        "    full_finetuning = False,\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 32,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha = 32,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ARM = \"rust\" or \"iron\"\n",
        "ARM = \"rust\"\n",
        "\n",
        "# Default local path for uploaded files\n",
        "BASE_DIR = \"/content/data/pilot/foundation_v1/unsloth\"\n",
        "\n",
        "# If using Google Drive, uncomment:\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# BASE_DIR = \"/content/drive/MyDrive/redox/data/pilot/foundation_v1/unsloth\"\n",
        "\n",
        "train_file = f\"{BASE_DIR}/{ARM}_train.jsonl\"\n",
        "val_file   = f\"{BASE_DIR}/{ARM}_val.jsonl\"\n",
        "test_file  = f\"{BASE_DIR}/{ARM}_test.jsonl\"\n",
        "\n",
        "print('Using arm:', ARM)\n",
        "print('Train:', train_file)\n",
        "print('Val:', val_file)\n",
        "print('Test:', test_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from unsloth.chat_templates import get_chat_template, standardize_data_formats\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files={\n",
        "        \"train\": train_file,\n",
        "        \"validation\": val_file,\n",
        "        \"test\": test_file,\n",
        "    },\n",
        ")\n",
        "\n",
        "train_dataset = dataset[\"train\"]\n",
        "val_dataset = dataset[\"validation\"]\n",
        "test_dataset = dataset[\"test\"]\n",
        "\n",
        "tokenizer = get_chat_template(tokenizer, chat_template=\"qwen3-instruct\")\n",
        "\n",
        "train_dataset = standardize_data_formats(train_dataset)\n",
        "val_dataset = standardize_data_formats(val_dataset)\n",
        "test_dataset = standardize_data_formats(test_dataset)\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    convos = examples[\"conversations\"]\n",
        "    texts = [\n",
        "        tokenizer.apply_chat_template(c, tokenize=False, add_generation_prompt=False)\n",
        "        for c in convos\n",
        "    ]\n",
        "    return {\"text\": texts}\n",
        "\n",
        "train_dataset = train_dataset.map(formatting_prompts_func, batched=True)\n",
        "val_dataset = val_dataset.map(formatting_prompts_func, batched=True)\n",
        "test_dataset = test_dataset.map(formatting_prompts_func, batched=True)\n",
        "\n",
        "print(dataset)\n",
        "print(train_dataset[0][\"text\"][:400])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from trl import SFTTrainer, SFTConfig\n",
        "from unsloth.chat_templates import train_on_responses_only\n",
        "\n",
        "run_name = f\"qwen3-4b-redox-{ARM}-seed3407\"\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    args=SFTConfig(\n",
        "        dataset_text_field=\"text\",\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        num_train_epochs=1,\n",
        "        learning_rate=2e-4,\n",
        "        logging_steps=10,\n",
        "        eval_steps=50,\n",
        "        eval_strategy=\"steps\",\n",
        "        save_steps=50,\n",
        "        save_total_limit=2,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.001,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        report_to=\"none\",\n",
        "        output_dir=f\"./outputs/{run_name}\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part=\"<|im_start|>user\\n\",\n",
        "    response_part=\"<|im_start|>assistant\\n\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_result = trainer.train()\n",
        "print(train_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_dir = f\"./outputs/qwen3-4b-redox-{ARM}-seed3407/final_adapter\"\n",
        "trainer.model.save_pretrained(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "print('Saved adapter to', save_dir)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
